name: Scraper Cron Job

on:
  schedule:
    # 11:00 UTC = 12:00 CET (Winter) / 13:00 CEST (Summer)
    - cron: '0 3 * * *'
  workflow_dispatch:
    inputs:
      league:
        description: 'League to scrape (optional, defaults to all)'
        required: false
        default: ''
      scope:
        description: 'Scrape Scope'
        required: true
        default: 'Last Round'
        type: choice
        options:
        - 'Last Round'
        - 'All Rounds'
      rescrape:
        description: 'Force Rescrape'
        required: false
        type: boolean
        default: false
      skip_analysis:
        description: 'Skip Gemini Analysis'
        required: false
        type: boolean
        default: true

jobs:
  scrape-league:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11' 

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f backend/requirements.txt ]; then pip install -r backend/requirements.txt; fi
    
    - name: Run Scraper for All Leagues
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
      run: |
        # Define defaults
        LEAGUES="eredivisie laliga serieb seriea bundesliga ligue1 premier"
        
        # Build arguments based on inputs/events
        COMMON_ARGS=""
        
        # Scope processing
        if [ "${{ github.event_name }}" == "schedule" ]; then
             COMMON_ARGS="$COMMON_ARGS --last-round"
        elif [ "${{ github.event.inputs.scope }}" == "Last Round" ]; then
             COMMON_ARGS="$COMMON_ARGS --last-round"
        fi

        # Skip Analysis processing
        if [ "${{ github.event_name }}" == "schedule" ]; then
             COMMON_ARGS="$COMMON_ARGS --skip-analysis"
        elif [ "${{ github.event.inputs.skip_analysis }}" == "true" ]; then
             COMMON_ARGS="$COMMON_ARGS --skip-analysis"
        fi

        # Rescrape processing
        if [ "${{ github.event_name }}" == "workflow_dispatch" ] && [ "${{ github.event.inputs.rescrape }}" == "true" ]; then
          COMMON_ARGS="$COMMON_ARGS --force-rescrape"
        fi

        # Filter specific league if input provided
        INPUT_LEAGUE="${{ github.event.inputs.league }}"
        if [ -n "$INPUT_LEAGUE" ]; then
          LEAGUES="$INPUT_LEAGUE"
        fi

        echo "Leagues to process: $LEAGUES"
        echo "Common Args: $COMMON_ARGS"

        # Loop through leagues
        FAILURES=0
        for LEAGUE in $LEAGUES; do
          echo "=========================================="
          echo "Running scraper for [$LEAGUE]"
          echo "=========================================="
          
          # Run the scraper, capture exit code but don't exit script immediately
          if ! python -m backend.scraper.main $LEAGUE $COMMON_ARGS; then
            echo "::error::Scraper failed for $LEAGUE"
            FAILURES=$((FAILURES+1))
          else
            echo "âœ… Finished $LEAGUE"
          fi
        done

        if [ $FAILURES -ne 0 ]; then
          echo "::error::Job finished with $FAILURES failed leagues."
          exit 1
        fi
        echo "All leagues processed successfully."
